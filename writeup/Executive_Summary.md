# Executive Summary

(1–2 pages; fill in results once experiments finish; one‑sentence question; 3 bullets of key results; one plot montage; one limitations paragraph.)

**Problem:** Do tiny transformers learn a linear 'sum' feature mediating predictions on conservation tasks?

**Approach:** Train tiny transformer → linear probes for `s=x+y` → projection ablation → activation patching → invariance checks → baselines.

**Key Results:** (fill in numbers/plots)

**Takeaways & Limitations:** (fill)

# Main write-up

(5-7 pages) Methods are clean and simple; Results organized by the three killer plots; Controls; Discussion (what did we learn about “model biology”?).

# Appendix / repro:

exact commands, seeds, config table; link to repo; short README.
